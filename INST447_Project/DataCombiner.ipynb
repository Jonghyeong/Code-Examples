{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this was initially a .py file instead of a jupyter notebook, \n",
    "#so the entire contents of the .py file has just been pasted into this chunk so that the code can be submitted as .html\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSN -> Movies and Shows (Netflix only)\n",
    "MSN = pd.read_csv('Netflix Movies and TV Shows.csv')\n",
    "#columns: show_id, type, title, director, cast, country, date_added, release_year, rating, duration, listed_in, description\n",
    "\n",
    "#Sho -> TV shows\n",
    "Sho = pd.read_csv('TV shows on Netflix, Prime Video, Hulu and Disney+.csv')\n",
    "#columns: Unnamed: 0, Title, Year, Age, IMDb, Rotten Tomatoes, Netflix, Hulu, Prime Video, Disney+, type\n",
    "\n",
    "#Mov -> Movies\n",
    "Mov = pd.read_csv('Movies on Netflix, Prime Video, Hulu and Disney+.csv')\n",
    "#columns: Unnamed: 0, Title, Year, Age, IMDb, Rotten Tomatoes, Netflix, Hulu, Prime Video, Disney+, Type, Directors, Genres, Country, Language, Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making MSN's column names the same as Sho and Mov's\n",
    "MSN.columns = ['show_id', 'type', 'Title', 'Directors', 'Cast', 'Country', 'date_added', 'Year', 'Flixable Rating', 'Runtime', 'Genres', 'description']\n",
    "\n",
    "#fixing Mov's Type column name\n",
    "Mov.rename(columns={'Type':'type'}, inplace=True)\n",
    "\n",
    "#Making Sho and Mov's 'type' column match MSN's\n",
    "def typeCleaner(row):\n",
    "    if row['type'] == 0:\n",
    "        return 'Movie'\n",
    "    elif row['type'] == 1:\n",
    "        return 'TV Show'\n",
    "    else:\n",
    "        #thankfully, this else never actually triggers, meaning Mov and Sho each only contain movies and shows, no strange extra formats (eg 'documentary', 'short film', etc)\n",
    "        print(row)\n",
    "        return row['type']\n",
    "\n",
    "#Applying the typeCleaner function to 'type' column in Sho and Mov dataset.\n",
    "Sho['type'] = Sho.apply(lambda row: typeCleaner(row), axis=1)\n",
    "Mov['type'] = Mov.apply(lambda row: typeCleaner(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making a csv of Mov and Sho\n",
    "Mov.to_csv('Mov.csv')\n",
    "Sho.to_csv('Sho.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining Mov and Sho\n",
    "\n",
    "#MTV = Movies and TV shows\n",
    "MTV = Mov.append(Sho)\n",
    "#columns: Unnamed: 0, Title, Year, Age, IMDb, Rotten Tomatoes, Netflix, Hulu, Prime Video, Disney+, Type, Directors, Genres, Country, Language, Runtime\n",
    "\n",
    "#Droping unnecessary columns\n",
    "MTV = MTV.drop(columns=['Unnamed: 0'])\n",
    "MSN = MSN.drop(columns=['show_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combing MSN and MTV into one final dataset\n",
    "#FDF = Final DataFrame\n",
    "FDF = MSN.merge(MTV, how='outer', on='Title')\n",
    "# The columns this made were a huge mess.  I did my best to line up everything, but there were conflicting values.\n",
    "# If you just want to drop all the rows with conflicting values, drop every row that has a string with ' or ' in it\n",
    "# if you want to keep the values from MSN when there's a conflict, split on ' or ' and take the first value in the list that returns\n",
    "# if you want to keep the values from MTV when there's a conflict, split on ' or ' and take the second value from the list that returns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining type columns\n",
    "def typeCombiner(row):\n",
    "    #if str(row['type_x']).strip == str(row['type_y']).strip:\n",
    "    if row['type_x'] == row['type_y']:\n",
    "        return row['type_x']\n",
    "    elif str(row['type_x']) == 'nan':\n",
    "        return row['type_y']\n",
    "    elif str(row['type_y']) == 'nan':\n",
    "        return row['type_x']\n",
    "    else:\n",
    "        #print(str(row['Title']) + ', ' + str(row['type_x']) + ', ' + str(row['type_y']))\n",
    "        return str(row['type_x']) + ' or ' + str(row['type_y'])\n",
    "\n",
    "FDF['type'] = FDF.apply(lambda row: typeCombiner(row), axis=1)\n",
    "FDF = FDF.drop(columns=['type_x', 'type_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning runtime columns\n",
    "def runtime_xCleaner(row):\n",
    "    if str(row['Runtime_x']) == 'nan':\n",
    "        return row['Runtime_x']\n",
    "    #elif str(row['Runtime_x']).find('Season') != -1:\n",
    "    elif 'Season' in str(row['Runtime_x']):\n",
    "        #print(str(row['Runtime_x']))\n",
    "        return row['Runtime_x']\n",
    "    else:\n",
    "        #print(str(row['Runtime_x']))\n",
    "        X = [int(i) for i in str(row['Runtime_x']).split() if i.isdigit()][0]\n",
    "        #print(X)\n",
    "        return str(X)\n",
    "\n",
    "def runtime_yCleaner(row):\n",
    "    if str(row['Runtime_y']) == 'nan':\n",
    "        return row['Runtime_y']\n",
    "    else:\n",
    "        Y = int(row['Runtime_y'])\n",
    "        #print(Y)\n",
    "        return str(Y)\n",
    "\n",
    "FDF['Runtime_x'] = FDF.apply(lambda row: runtime_xCleaner(row), axis=1)\n",
    "FDF['Runtime_y'] = FDF.apply(lambda row: runtime_yCleaner(row), axis=1)\n",
    "\n",
    "#combining runtime columns\n",
    "def runtimeCombiner(row):\n",
    "    if row['Runtime_x'] == row['Runtime_y']:\n",
    "        return row['Runtime_x']\n",
    "    elif str(row['Runtime_x']) == 'nan':\n",
    "        return row['Runtime_y']\n",
    "    elif str(row['Runtime_y']) == 'nan':\n",
    "        return row['Runtime_x']\n",
    "    else:\n",
    "        #print(str(row['Runtime_x']) + ' or ' + str(row['Runtime_y']))\n",
    "        return str(row['Runtime_x']) + ' or ' + str(row['Runtime_y'])\n",
    "\n",
    "FDF['Runtime'] = FDF.apply(lambda row: runtimeCombiner(row), axis=1)\n",
    "FDF = FDF.drop(columns=['Runtime_x', 'Runtime_y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining directors columns\n",
    "from difflib import SequenceMatcher\n",
    "def similarity(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def directorsCombiner(row):\n",
    "    if row['Directors_x'] == row['Directors_y']:\n",
    "        return row['Directors_x']\n",
    "    elif str(row['Directors_x']) == 'nan':\n",
    "        return row['Directors_y']\n",
    "    elif str(row['Directors_y']) == 'nan':\n",
    "        return row['Directors_x']\n",
    "    #this small block checks how similar the two column values are, and if they're somewhat similar it takes the longer of the two as the correct value\n",
    "    elif similarity(str(row['Directors_x']), str(row['Directors_y'])) >= 0.33:\n",
    "        #print('close enough')\n",
    "        if len(str(row['Directors_y'])) > len(str(row['Directors_x'])):\n",
    "            return row['Directors_y']\n",
    "        else:\n",
    "            return row['Directors_x']\n",
    "    else:\n",
    "        #print('no dice')\n",
    "        #print(str(row['Directors_x']) + ' or ' + str(row['Directors_y']))\n",
    "        return str(row['Directors_x']) + ' or ' + str(row['Directors_y'])\n",
    "\n",
    "FDF['Directors'] = FDF.apply(lambda row: directorsCombiner(row), axis=1)\n",
    "FDF = FDF.drop(columns=['Directors_x', 'Directors_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combining country columns\n",
    "def countryCombiner(row):\n",
    "    if row['Country_x'] == row['Country_y']:\n",
    "        return row['Country_x']\n",
    "    elif str(row['Country_x']) == 'nan':\n",
    "        return row['Country_y']\n",
    "    elif str(row['Country_y']) == 'nan':\n",
    "        return row['Country_x']\n",
    "    #this small block checks how similar the two column values are, and if they're somewhat similar it takes the longer of the two as the correct value\n",
    "    elif similarity(str(row['Country_x']), str(row['Country_y'])) >= 0.33:\n",
    "        if len(str(row['Country_y'])) > len(str(row['Country_x'])):\n",
    "            return row['Country_y']\n",
    "        else:\n",
    "            return row['Country_x']\n",
    "    else:\n",
    "        return str(row['Country_x']) + ' or ' + str(row['Country_y'])\n",
    "\n",
    "FDF['Country'] = FDF.apply(lambda row: countryCombiner(row), axis=1)\n",
    "FDF = FDF.drop(columns=['Country_x', 'Country_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning year columns\n",
    "def year_xCleaner(row):\n",
    "    if str(row['Year_x']) == 'nan':\n",
    "        return row['Year_x']\n",
    "    else:\n",
    "        X = int(row['Year_x'])\n",
    "        #print(X)\n",
    "        return str(X)\n",
    "\n",
    "def year_yCleaner(row):\n",
    "    if str(row['Year_y']) == 'nan':\n",
    "        return row['Year_y']\n",
    "    else:\n",
    "        Y = int(row['Year_y'])\n",
    "        #print(Y)\n",
    "        return str(Y)\n",
    "\n",
    "FDF['Year_x'] = FDF.apply(lambda row: year_xCleaner(row), axis=1)\n",
    "FDF['Year_y'] = FDF.apply(lambda row: year_yCleaner(row), axis=1)\n",
    "\n",
    "#combining year columns\n",
    "def yearCombiner(row):\n",
    "    if str(row['Year_x']) == str(row['Year_y']):\n",
    "        return row['Year_x']\n",
    "    elif str(row['Year_x']) == 'nan':\n",
    "        return row['Year_y']\n",
    "    elif str(row['Year_y']) == 'nan':\n",
    "        return row['Year_x']\n",
    "    else:\n",
    "        return str(row['Year_x']) + ' or ' + str(row['Year_y'])\n",
    "\n",
    "FDF['Year'] = FDF.apply(lambda row: yearCombiner(row), axis=1)\n",
    "FDF = FDF.drop(columns=['Year_x', 'Year_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25652 entries, 0 to 25651\n",
      "Data columns (total 20 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Title            25652 non-null  object \n",
      " 1   Cast             7085 non-null   object \n",
      " 2   date_added       7794 non-null   object \n",
      " 3   Flixable Rating  7797 non-null   object \n",
      " 4   Genres_x         7804 non-null   object \n",
      " 5   description      7804 non-null   object \n",
      " 6   Age              10519 non-null  object \n",
      " 7   IMDb             20623 non-null  float64\n",
      " 8   Rotten Tomatoes  6169 non-null   object \n",
      " 9   Netflix          22355 non-null  float64\n",
      " 10  Hulu             22355 non-null  float64\n",
      " 11  Prime Video      22355 non-null  float64\n",
      " 12  Disney+          22355 non-null  float64\n",
      " 13  Genres_y         16469 non-null  object \n",
      " 14  Language         16145 non-null  object \n",
      " 15  type             25652 non-null  object \n",
      " 16  Runtime          21072 non-null  object \n",
      " 17  Directors        18576 non-null  object \n",
      " 18  Country          20706 non-null  object \n",
      " 19  Year             25652 non-null  object \n",
      "dtypes: float64(5), object(15)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "FDF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'date_added', 'description', 'Age', 'IMDb', 'Rotten Tomatoes',\n",
       "       'Netflix', 'Hulu', 'Prime Video', 'Disney+', 'Language', 'type',\n",
       "       'Runtime', 'Directors', 'Country', 'Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From the final dataset, \n",
    "#Drop unnecessary columns and keep only columns needed for this project\n",
    "FDF = FDF.drop(columns=['Cast','Flixable Rating','Genres_x','Genres_y'])\n",
    "FDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making csv for FDF\n",
    "FDF.to_csv(\"FDF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
